{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alboulayan_selfstudy11_bert.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoneerahAlboulayan/info5731/blob/master/Alboulayan_selfstudy11_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dolGoXwTauJl",
        "colab_type": "code",
        "outputId": "0c0e4fcf-c5ba-4efe-dfc9-395a5f183695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install bert-text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-text\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/1d/3c7226547cd6a2ba54586dfd80a49f64a0936f9bcb945a4686e843a1956a/bert_text-5.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from bert-text) (0.23.4)\n",
            "Collecting bert-tensorflow (from bert-text)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (from bert-text) (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-text) (1.11.0)\n",
            "Collecting tensorflow-gpu (from bert-text)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 345.2MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bert-text) (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas->bert-text) (1.16.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->bert-text) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->bert-text) (2.5.3)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub->bert-text) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.0.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.0.9)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.33.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu->bert-text) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub->bert-text) (40.9.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu->bert-text) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu->bert-text) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu->bert-text) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu->bert-text) (0.15.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu->bert-text) (5.1.3)\n",
            "Installing collected packages: bert-tensorflow, tensorflow-gpu, bert-text\n",
            "Successfully installed bert-tensorflow-1.0.1 bert-text-5.0.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MJIFFAZAa-Zq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dcf7c82c-31a8-4584-b939-3622db518605"
      },
      "cell_type": "code",
      "source": [
        "from bert_text import run_on_dfs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0415 18:23:11.519089 140216261453696 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "keYcuTsma-dO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hx4NiG3Da-fy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('imdb-review (1).pickle', 'rb') as f:\n",
        "  train, test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wfjCSUPma-jD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "myparam = {\n",
        "    \"DATA_COLUMN\": \"text\",\n",
        "    \"LABEL_COLUMN\": \"sentiment\",\n",
        "    \"LEARNING_RATE\": 2e-5,\n",
        "    \"NUM_TRAIN_EPOCHS\": 3\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hb-WUWGga-n_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xlft95sTbupJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4780
        },
        "outputId": "53a63a61-2e89-4941-bfa7-3eaa888e8362"
      },
      "cell_type": "code",
      "source": [
        "result, estimator = run_on_dfs(train, test, **myparam)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:12.323853 140216261453696 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.502240 140216261453696 run_classifier.py:774] Writing example 0 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.506485 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.514470 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem . imagine a movie where joe pi ##sco ##po is actually funny ! maureen staple ##ton is a scene steal ##er . the mor ##oni character is an absolute scream . watch for alan \" the skipper \" hale jr . as a police sgt . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.519016 140216261453696 run_classifier.py:464] tokens: [CLS] for a movie that gets no respect there sure are a lot of memorable quotes listed for this gem . imagine a movie where joe pi ##sco ##po is actually funny ! maureen staple ##ton is a scene steal ##er . the mor ##oni character is an absolute scream . watch for alan \" the skipper \" hale jr . as a police sgt . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2005 1037 3185 2008 4152 2053 4847 2045 2469 2024 1037 2843 1997 13432 16614 3205 2005 2023 17070 1012 5674 1037 3185 2073 3533 14255 9363 6873 2003 2941 6057 999 19167 18785 2669 2003 1037 3496 8954 2121 1012 1996 22822 10698 2839 2003 2019 7619 6978 1012 3422 2005 5070 1000 1996 23249 1000 13084 3781 1012 2004 1037 2610 17001 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.523449 140216261453696 run_classifier.py:465] input_ids: 101 2005 1037 3185 2008 4152 2053 4847 2045 2469 2024 1037 2843 1997 13432 16614 3205 2005 2023 17070 1012 5674 1037 3185 2073 3533 14255 9363 6873 2003 2941 6057 999 19167 18785 2669 2003 1037 3496 8954 2121 1012 1996 22822 10698 2839 2003 2019 7619 6978 1012 3422 2005 5070 1000 1996 23249 1000 13084 3781 1012 2004 1037 2610 17001 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.527690 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.531924 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.536069 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.548170 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.551007 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bizarre horror movie filled with famous faces but stolen by cristina rain ##es ( later of tv ' s \" flaming ##o road \" ) as a pretty but somewhat unstable model with a gum ##my smile who is slated to pay for her attempted suicide ##s by guarding the gateway to hell ! the scenes with rain ##es modeling are very well captured , the mood music is perfect , deborah raf ##fin is charming as cristina ' s pal , but when rain ##es moves into a creepy brooklyn heights browns ##tone ( inhabited by a blind priest on the top floor ) , things really start cooking . the neighbors , including a fantastic ##ally wicked burgess meredith and kin ##ky couple sylvia [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.556358 140216261453696 run_classifier.py:464] tokens: [CLS] bizarre horror movie filled with famous faces but stolen by cristina rain ##es ( later of tv ' s \" flaming ##o road \" ) as a pretty but somewhat unstable model with a gum ##my smile who is slated to pay for her attempted suicide ##s by guarding the gateway to hell ! the scenes with rain ##es modeling are very well captured , the mood music is perfect , deborah raf ##fin is charming as cristina ' s pal , but when rain ##es moves into a creepy brooklyn heights browns ##tone ( inhabited by a blind priest on the top floor ) , things really start cooking . the neighbors , including a fantastic ##ally wicked burgess meredith and kin ##ky couple sylvia [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 13576 5469 3185 3561 2007 3297 5344 2021 7376 2011 22246 4542 2229 1006 2101 1997 2694 1005 1055 1000 19091 2080 2346 1000 1007 2004 1037 3492 2021 5399 14480 2944 2007 1037 16031 8029 2868 2040 2003 18517 2000 3477 2005 2014 4692 5920 2015 2011 17019 1996 11909 2000 3109 999 1996 5019 2007 4542 2229 11643 2024 2200 2092 4110 1010 1996 6888 2189 2003 3819 1010 15555 7148 16294 2003 11951 2004 22246 1005 1055 14412 1010 2021 2043 4542 2229 5829 2046 1037 17109 6613 7535 13240 5524 1006 9613 2011 1037 6397 5011 2006 1996 2327 2723 1007 1010 2477 2428 2707 8434 1012 1996 10638 1010 2164 1037 10392 3973 10433 17754 10635 1998 12631 4801 3232 13378 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.572667 140216261453696 run_classifier.py:465] input_ids: 101 13576 5469 3185 3561 2007 3297 5344 2021 7376 2011 22246 4542 2229 1006 2101 1997 2694 1005 1055 1000 19091 2080 2346 1000 1007 2004 1037 3492 2021 5399 14480 2944 2007 1037 16031 8029 2868 2040 2003 18517 2000 3477 2005 2014 4692 5920 2015 2011 17019 1996 11909 2000 3109 999 1996 5019 2007 4542 2229 11643 2024 2200 2092 4110 1010 1996 6888 2189 2003 3819 1010 15555 7148 16294 2003 11951 2004 22246 1005 1055 14412 1010 2021 2043 4542 2229 5829 2046 1037 17109 6613 7535 13240 5524 1006 9613 2011 1037 6397 5011 2006 1996 2327 2723 1007 1010 2477 2428 2707 8434 1012 1996 10638 1010 2164 1037 10392 3973 10433 17754 10635 1998 12631 4801 3232 13378 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.580664 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.589386 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.593477 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.600467 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.604358 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a solid , if un ##rem ##ark ##able film . matt ##ha ##u , as einstein , was wonderful . my favorite part , and the only thing that would make me go out of my way to see this again , was the wonderful scene with the physicist ##s playing bad ##mit ##ton , i loved the sweater ##s and the conversation while they waited for robbins to retrieve the bird ##ie . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.608383 140216261453696 run_classifier.py:464] tokens: [CLS] a solid , if un ##rem ##ark ##able film . matt ##ha ##u , as einstein , was wonderful . my favorite part , and the only thing that would make me go out of my way to see this again , was the wonderful scene with the physicist ##s playing bad ##mit ##ton , i loved the sweater ##s and the conversation while they waited for robbins to retrieve the bird ##ie . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 5024 1010 2065 4895 28578 17007 3085 2143 1012 4717 3270 2226 1010 2004 15313 1010 2001 6919 1012 2026 5440 2112 1010 1998 1996 2069 2518 2008 2052 2191 2033 2175 2041 1997 2026 2126 2000 2156 2023 2153 1010 2001 1996 6919 3496 2007 1996 13702 2015 2652 2919 22930 2669 1010 1045 3866 1996 14329 2015 1998 1996 4512 2096 2027 4741 2005 18091 2000 12850 1996 4743 2666 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.612350 140216261453696 run_classifier.py:465] input_ids: 101 1037 5024 1010 2065 4895 28578 17007 3085 2143 1012 4717 3270 2226 1010 2004 15313 1010 2001 6919 1012 2026 5440 2112 1010 1998 1996 2069 2518 2008 2052 2191 2033 2175 2041 1997 2026 2126 2000 2156 2023 2153 1010 2001 1996 6919 3496 2007 1996 13702 2015 2652 2919 22930 2669 1010 1045 3866 1996 14329 2015 1998 1996 4512 2096 2027 4741 2005 18091 2000 12850 1996 4743 2666 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.616007 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.988421 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:13.994393 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.014632 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.017846 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] it ' s a strange feeling to sit alone in a theater occupied by parents and their roll ##ick ##ing kids . i felt like instead of a movie ticket , i should have been given a nam ##bla membership . < br / > < br / > based upon thomas rockwell ' s respected book , how to eat fried worms starts like any children ' s story : moving to a new town . the new kid , fifth grade ##r billy forrest ##er was once popular , but has to start an ##ew . making friends is never easy , especially when the only prospect is po ##ind ##ex ##ter adam . or erica , who at 4 1 / 2 feet [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.021287 140216261453696 run_classifier.py:464] tokens: [CLS] it ' s a strange feeling to sit alone in a theater occupied by parents and their roll ##ick ##ing kids . i felt like instead of a movie ticket , i should have been given a nam ##bla membership . < br / > < br / > based upon thomas rockwell ' s respected book , how to eat fried worms starts like any children ' s story : moving to a new town . the new kid , fifth grade ##r billy forrest ##er was once popular , but has to start an ##ew . making friends is never easy , especially when the only prospect is po ##ind ##ex ##ter adam . or erica , who at 4 1 / 2 feet [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2009 1005 1055 1037 4326 3110 2000 4133 2894 1999 1037 4258 4548 2011 3008 1998 2037 4897 6799 2075 4268 1012 1045 2371 2066 2612 1997 1037 3185 7281 1010 1045 2323 2031 2042 2445 1037 15125 28522 5779 1012 1026 7987 1013 1028 1026 7987 1013 1028 2241 2588 2726 25235 1005 1055 9768 2338 1010 2129 2000 4521 13017 16253 4627 2066 2151 2336 1005 1055 2466 1024 3048 2000 1037 2047 2237 1012 1996 2047 4845 1010 3587 3694 2099 5006 16319 2121 2001 2320 2759 1010 2021 2038 2000 2707 2019 7974 1012 2437 2814 2003 2196 3733 1010 2926 2043 1996 2069 9824 2003 13433 22254 10288 3334 4205 1012 2030 19295 1010 2040 2012 1018 1015 1013 1016 2519 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.037659 140216261453696 run_classifier.py:465] input_ids: 101 2009 1005 1055 1037 4326 3110 2000 4133 2894 1999 1037 4258 4548 2011 3008 1998 2037 4897 6799 2075 4268 1012 1045 2371 2066 2612 1997 1037 3185 7281 1010 1045 2323 2031 2042 2445 1037 15125 28522 5779 1012 1026 7987 1013 1028 1026 7987 1013 1028 2241 2588 2726 25235 1005 1055 9768 2338 1010 2129 2000 4521 13017 16253 4627 2066 2151 2336 1005 1055 2466 1024 3048 2000 1037 2047 2237 1012 1996 2047 4845 1010 3587 3694 2099 5006 16319 2121 2001 2320 2759 1010 2021 2038 2000 2707 2019 7974 1012 2437 2814 2003 2196 3733 1010 2926 2043 1996 2069 9824 2003 13433 22254 10288 3334 4205 1012 2030 19295 1010 2040 2012 1018 1015 1013 1016 2519 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.041158 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.044824 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.050138 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.060638 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.065030 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] you probably all already know this by now , but 5 additional episodes never aired can be viewed on abc . com i ' ve watched a lot of television over the years and this is possibly my favorite show , ever . it ' s a crime that this beautifully written and acted show was canceled . the actors that played laura , w ##hit , carlos , mae , damian , anya and om ##g , steven case ##man - are all incredible and so natural in those roles . even the kids are great . wonderful show . so sad that it ' s gone . of course i wonder about the reasons it was canceled . there is no way i ' [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.070384 140216261453696 run_classifier.py:464] tokens: [CLS] you probably all already know this by now , but 5 additional episodes never aired can be viewed on abc . com i ' ve watched a lot of television over the years and this is possibly my favorite show , ever . it ' s a crime that this beautifully written and acted show was canceled . the actors that played laura , w ##hit , carlos , mae , damian , anya and om ##g , steven case ##man - are all incredible and so natural in those roles . even the kids are great . wonderful show . so sad that it ' s gone . of course i wonder about the reasons it was canceled . there is no way i ' [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2017 2763 2035 2525 2113 2023 2011 2085 1010 2021 1019 3176 4178 2196 4836 2064 2022 7021 2006 5925 1012 4012 1045 1005 2310 3427 1037 2843 1997 2547 2058 1996 2086 1998 2023 2003 4298 2026 5440 2265 1010 2412 1012 2009 1005 1055 1037 4126 2008 2023 17950 2517 1998 6051 2265 2001 13261 1012 1996 5889 2008 2209 6874 1010 1059 16584 1010 5828 1010 11530 1010 19507 1010 21728 1998 18168 2290 1010 7112 2553 2386 1011 2024 2035 9788 1998 2061 3019 1999 2216 4395 1012 2130 1996 4268 2024 2307 1012 6919 2265 1012 2061 6517 2008 2009 1005 1055 2908 1012 1997 2607 1045 4687 2055 1996 4436 2009 2001 13261 1012 2045 2003 2053 2126 1045 1005 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.073626 140216261453696 run_classifier.py:465] input_ids: 101 2017 2763 2035 2525 2113 2023 2011 2085 1010 2021 1019 3176 4178 2196 4836 2064 2022 7021 2006 5925 1012 4012 1045 1005 2310 3427 1037 2843 1997 2547 2058 1996 2086 1998 2023 2003 4298 2026 5440 2265 1010 2412 1012 2009 1005 1055 1037 4126 2008 2023 17950 2517 1998 6051 2265 2001 13261 1012 1996 5889 2008 2209 6874 1010 1059 16584 1010 5828 1010 11530 1010 19507 1010 21728 1998 18168 2290 1010 7112 2553 2386 1011 2024 2035 9788 1998 2061 3019 1999 2216 4395 1012 2130 1996 4268 2024 2307 1012 6919 2265 1012 2061 6517 2008 2009 1005 1055 2908 1012 1997 2607 1045 4687 2055 1996 4436 2009 2001 13261 1012 2045 2003 2053 2126 1045 1005 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.077064 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.080541 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:28:14.083983 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:29:02.638274 140216261453696 run_classifier.py:774] Writing example 10000 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:29:46.729221 140216261453696 run_classifier.py:774] Writing example 20000 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.330948 140216261453696 run_classifier.py:774] Writing example 0 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.339765 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.342785 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] based on an actual story , john boo ##rman shows the struggle of an american doctor , whose husband and son were murdered and she was continually plagued with her loss . a holiday to burma with her sister seemed like a good idea to get away from it all , but when her passport was stolen in rang ##oon , she could not leave the country with her sister , and was forced to stay back until she could get i . d . papers from the american embassy . to fill in a day before she could fly out , she took a trip into the countryside with a tour guide . \" i tried finding something in those stone statues , but nothing [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.346270 140216261453696 run_classifier.py:464] tokens: [CLS] based on an actual story , john boo ##rman shows the struggle of an american doctor , whose husband and son were murdered and she was continually plagued with her loss . a holiday to burma with her sister seemed like a good idea to get away from it all , but when her passport was stolen in rang ##oon , she could not leave the country with her sister , and was forced to stay back until she could get i . d . papers from the american embassy . to fill in a day before she could fly out , she took a trip into the countryside with a tour guide . \" i tried finding something in those stone statues , but nothing [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2241 2006 2019 5025 2466 1010 2198 22017 14515 3065 1996 5998 1997 2019 2137 3460 1010 3005 3129 1998 2365 2020 7129 1998 2016 2001 14678 17808 2007 2014 3279 1012 1037 6209 2000 11050 2007 2014 2905 2790 2066 1037 2204 2801 2000 2131 2185 2013 2009 2035 1010 2021 2043 2014 12293 2001 7376 1999 8369 7828 1010 2016 2071 2025 2681 1996 2406 2007 2014 2905 1010 1998 2001 3140 2000 2994 2067 2127 2016 2071 2131 1045 1012 1040 1012 4981 2013 1996 2137 8408 1012 2000 6039 1999 1037 2154 2077 2016 2071 4875 2041 1010 2016 2165 1037 4440 2046 1996 10833 2007 1037 2778 5009 1012 1000 1045 2699 4531 2242 1999 2216 2962 11342 1010 2021 2498 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.351252 140216261453696 run_classifier.py:465] input_ids: 101 2241 2006 2019 5025 2466 1010 2198 22017 14515 3065 1996 5998 1997 2019 2137 3460 1010 3005 3129 1998 2365 2020 7129 1998 2016 2001 14678 17808 2007 2014 3279 1012 1037 6209 2000 11050 2007 2014 2905 2790 2066 1037 2204 2801 2000 2131 2185 2013 2009 2035 1010 2021 2043 2014 12293 2001 7376 1999 8369 7828 1010 2016 2071 2025 2681 1996 2406 2007 2014 2905 1010 1998 2001 3140 2000 2994 2067 2127 2016 2071 2131 1045 1012 1040 1012 4981 2013 1996 2137 8408 1012 2000 6039 1999 1037 2154 2077 2016 2071 4875 2041 1010 2016 2165 1037 4440 2046 1996 10833 2007 1037 2778 5009 1012 1000 1045 2699 4531 2242 1999 2216 2962 11342 1010 2021 2498 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.357334 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.359872 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.365666 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.377711 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.384443 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this is a gem . as a film four production - the anticipated quality was indeed delivered . shot with great style that reminded me some er ##rol morris films , well arranged and simply gripping . it ' s long yet ho ##rri ##fying to the point it ' s ex ##cr ##uc ##iating . we know something bad happened ( one can guess by the lack of participation of a person in the interviews ) but we are compelled to see it , a bit like a car accident in slow motion . the story spans most con ##ce ##iva ##ble aspects and unlike some documentaries did not try and refrain from showing the grimm ##er sides of the stories , as also dealing [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.393626 140216261453696 run_classifier.py:464] tokens: [CLS] this is a gem . as a film four production - the anticipated quality was indeed delivered . shot with great style that reminded me some er ##rol morris films , well arranged and simply gripping . it ' s long yet ho ##rri ##fying to the point it ' s ex ##cr ##uc ##iating . we know something bad happened ( one can guess by the lack of participation of a person in the interviews ) but we are compelled to see it , a bit like a car accident in slow motion . the story spans most con ##ce ##iva ##ble aspects and unlike some documentaries did not try and refrain from showing the grimm ##er sides of the stories , as also dealing [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2003 1037 17070 1012 2004 1037 2143 2176 2537 1011 1996 11436 3737 2001 5262 5359 1012 2915 2007 2307 2806 2008 6966 2033 2070 9413 13153 6384 3152 1010 2092 5412 1998 3432 13940 1012 2009 1005 1055 2146 2664 7570 18752 14116 2000 1996 2391 2009 1005 1055 4654 26775 14194 15370 1012 2057 2113 2242 2919 3047 1006 2028 2064 3984 2011 1996 3768 1997 6577 1997 1037 2711 1999 1996 7636 1007 2021 2057 2024 15055 2000 2156 2009 1010 1037 2978 2066 1037 2482 4926 1999 4030 4367 1012 1996 2466 14798 2087 9530 3401 11444 3468 5919 1998 4406 2070 15693 2106 2025 3046 1998 20703 2013 4760 1996 24287 2121 3903 1997 1996 3441 1010 2004 2036 7149 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.398061 140216261453696 run_classifier.py:465] input_ids: 101 2023 2003 1037 17070 1012 2004 1037 2143 2176 2537 1011 1996 11436 3737 2001 5262 5359 1012 2915 2007 2307 2806 2008 6966 2033 2070 9413 13153 6384 3152 1010 2092 5412 1998 3432 13940 1012 2009 1005 1055 2146 2664 7570 18752 14116 2000 1996 2391 2009 1005 1055 4654 26775 14194 15370 1012 2057 2113 2242 2919 3047 1006 2028 2064 3984 2011 1996 3768 1997 6577 1997 1037 2711 1999 1996 7636 1007 2021 2057 2024 15055 2000 2156 2009 1010 1037 2978 2066 1037 2482 4926 1999 4030 4367 1012 1996 2466 14798 2087 9530 3401 11444 3468 5919 1998 4406 2070 15693 2106 2025 3046 1998 20703 2013 4760 1996 24287 2121 3903 1997 1996 3441 1010 2004 2036 7149 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.404856 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.414371 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.419741 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.429497 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.432440 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i really like this show . it has drama , romance , and comedy all rolled into one . i am 28 and i am a married mother , so i can identify both with lore ##lei ' s and rory ' s experiences in the show . i have been watching mostly the repeats on the family channel lately , so i am not up - to - date on what is going on now . i think females would like this show more than males , but i know some men out there would enjoy it ! i really like that is an hour long and not a half hour , as th hour seems to fly by when i am watching it ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.436171 140216261453696 run_classifier.py:464] tokens: [CLS] i really like this show . it has drama , romance , and comedy all rolled into one . i am 28 and i am a married mother , so i can identify both with lore ##lei ' s and rory ' s experiences in the show . i have been watching mostly the repeats on the family channel lately , so i am not up - to - date on what is going on now . i think females would like this show more than males , but i know some men out there would enjoy it ! i really like that is an hour long and not a half hour , as th hour seems to fly by when i am watching it ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2428 2066 2023 2265 1012 2009 2038 3689 1010 7472 1010 1998 4038 2035 4565 2046 2028 1012 1045 2572 2654 1998 1045 2572 1037 2496 2388 1010 2061 1045 2064 6709 2119 2007 19544 23057 1005 1055 1998 14285 1005 1055 6322 1999 1996 2265 1012 1045 2031 2042 3666 3262 1996 17993 2006 1996 2155 3149 9906 1010 2061 1045 2572 2025 2039 1011 2000 1011 3058 2006 2054 2003 2183 2006 2085 1012 1045 2228 3801 2052 2066 2023 2265 2062 2084 3767 1010 2021 1045 2113 2070 2273 2041 2045 2052 5959 2009 999 1045 2428 2066 2008 2003 2019 3178 2146 1998 2025 1037 2431 3178 1010 2004 16215 3178 3849 2000 4875 2011 2043 1045 2572 3666 2009 999 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.441225 140216261453696 run_classifier.py:465] input_ids: 101 1045 2428 2066 2023 2265 1012 2009 2038 3689 1010 7472 1010 1998 4038 2035 4565 2046 2028 1012 1045 2572 2654 1998 1045 2572 1037 2496 2388 1010 2061 1045 2064 6709 2119 2007 19544 23057 1005 1055 1998 14285 1005 1055 6322 1999 1996 2265 1012 1045 2031 2042 3666 3262 1996 17993 2006 1996 2155 3149 9906 1010 2061 1045 2572 2025 2039 1011 2000 1011 3058 2006 2054 2003 2183 2006 2085 1012 1045 2228 3801 2052 2066 2023 2265 2062 2084 3767 1010 2021 1045 2113 2070 2273 2041 2045 2052 5959 2009 999 1045 2428 2066 2008 2003 2019 3178 2146 1998 2025 1037 2431 3178 1010 2004 16215 3178 3849 2000 4875 2011 2043 1045 2572 3666 2009 999 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.444839 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.447983 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.452469 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.460565 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.464314 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this is the best 3 - d experience disney has at their theme ##park ##s . this is certainly better than their original 1960 ' s acid - trip film that was in it ' s place , is leagues better than \" honey i sh ##run ##k the audience \" ( and far more fun ) , barely squeak ##s by the mu ##ppet ##vision 3 - d movie at disney - mgm and can even beat the original 3 - d \" movie experience \" captain e ##o . this film re ##li ##ves some of disney ' s greatest musical hits from ala ##ddin , the little mermaid , and others , and brought a smile to my face throughout the entire show [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.467400 140216261453696 run_classifier.py:464] tokens: [CLS] this is the best 3 - d experience disney has at their theme ##park ##s . this is certainly better than their original 1960 ' s acid - trip film that was in it ' s place , is leagues better than \" honey i sh ##run ##k the audience \" ( and far more fun ) , barely squeak ##s by the mu ##ppet ##vision 3 - d movie at disney - mgm and can even beat the original 3 - d \" movie experience \" captain e ##o . this film re ##li ##ves some of disney ' s greatest musical hits from ala ##ddin , the little mermaid , and others , and brought a smile to my face throughout the entire show [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2003 1996 2190 1017 1011 1040 3325 6373 2038 2012 2037 4323 14432 2015 1012 2023 2003 5121 2488 2084 2037 2434 3624 1005 1055 5648 1011 4440 2143 2008 2001 1999 2009 1005 1055 2173 1010 2003 8121 2488 2084 1000 6861 1045 14021 15532 2243 1996 4378 1000 1006 1998 2521 2062 4569 1007 1010 4510 29552 2015 2011 1996 14163 29519 17084 1017 1011 1040 3185 2012 6373 1011 15418 1998 2064 2130 3786 1996 2434 1017 1011 1040 1000 3185 3325 1000 2952 1041 2080 1012 2023 2143 2128 3669 6961 2070 1997 6373 1005 1055 4602 3315 4978 2013 21862 18277 1010 1996 2210 22322 1010 1998 2500 1010 1998 2716 1037 2868 2000 2026 2227 2802 1996 2972 2265 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.471252 140216261453696 run_classifier.py:465] input_ids: 101 2023 2003 1996 2190 1017 1011 1040 3325 6373 2038 2012 2037 4323 14432 2015 1012 2023 2003 5121 2488 2084 2037 2434 3624 1005 1055 5648 1011 4440 2143 2008 2001 1999 2009 1005 1055 2173 1010 2003 8121 2488 2084 1000 6861 1045 14021 15532 2243 1996 4378 1000 1006 1998 2521 2062 4569 1007 1010 4510 29552 2015 2011 1996 14163 29519 17084 1017 1011 1040 3185 2012 6373 1011 15418 1998 2064 2130 3786 1996 2434 1017 1011 1040 1000 3185 3325 1000 2952 1041 2080 1012 2023 2143 2128 3669 6961 2070 1997 6373 1005 1055 4602 3315 4978 2013 21862 18277 1010 1996 2210 22322 1010 1998 2500 1010 1998 2716 1037 2868 2000 2026 2227 2802 1996 2972 2265 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.475552 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.478484 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.482774 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.494635 140216261453696 run_classifier.py:461] *** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.498524 140216261453696 run_classifier.py:462] guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] of the korean movies i ' ve seen , only three had really stuck with me . the first is the excellent horror a tale of two sisters . the second and third - and now fourth too - have all been park chan woo ##k ' s movies , namely old ##boy , sympathy for lady vengeance ) , and now thirst . < br / > < br / > park kinda reminds me of quentin tara ##ntino with his ir ##re ##vere ##nce towards convention . all his movies are shocking , but not in a gr ##at ##uit ##ous sense . it ' s more like he shows us what we don ' t expect to see - typically situations that go [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.501662 140216261453696 run_classifier.py:464] tokens: [CLS] of the korean movies i ' ve seen , only three had really stuck with me . the first is the excellent horror a tale of two sisters . the second and third - and now fourth too - have all been park chan woo ##k ' s movies , namely old ##boy , sympathy for lady vengeance ) , and now thirst . < br / > < br / > park kinda reminds me of quentin tara ##ntino with his ir ##re ##vere ##nce towards convention . all his movies are shocking , but not in a gr ##at ##uit ##ous sense . it ' s more like he shows us what we don ' t expect to see - typically situations that go [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1997 1996 4759 5691 1045 1005 2310 2464 1010 2069 2093 2018 2428 5881 2007 2033 1012 1996 2034 2003 1996 6581 5469 1037 6925 1997 2048 5208 1012 1996 2117 1998 2353 1011 1998 2085 2959 2205 1011 2031 2035 2042 2380 9212 15854 2243 1005 1055 5691 1010 8419 2214 11097 1010 11883 2005 3203 14096 1007 1010 1998 2085 21810 1012 1026 7987 1013 1028 1026 7987 1013 1028 2380 17704 15537 2033 1997 15969 10225 25318 2007 2010 20868 2890 28943 5897 2875 4680 1012 2035 2010 5691 2024 16880 1010 2021 2025 1999 1037 24665 4017 14663 3560 3168 1012 2009 1005 1055 2062 2066 2002 3065 2149 2054 2057 2123 1005 1056 5987 2000 2156 1011 4050 8146 2008 2175 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.505913 140216261453696 run_classifier.py:465] input_ids: 101 1997 1996 4759 5691 1045 1005 2310 2464 1010 2069 2093 2018 2428 5881 2007 2033 1012 1996 2034 2003 1996 6581 5469 1037 6925 1997 2048 5208 1012 1996 2117 1998 2353 1011 1998 2085 2959 2205 1011 2031 2035 2042 2380 9212 15854 2243 1005 1055 5691 1010 8419 2214 11097 1010 11883 2005 3203 14096 1007 1010 1998 2085 21810 1012 1026 7987 1013 1028 1026 7987 1013 1028 2380 17704 15537 2033 1997 15969 10225 25318 2007 2010 20868 2890 28943 5897 2875 4680 1012 2035 2010 5691 2024 16880 1010 2021 2025 1999 1037 24665 4017 14663 3560 3168 1012 2009 1005 1055 2062 2066 2002 3065 2149 2054 2057 2123 1005 1056 5987 2000 2156 1011 4050 8146 2008 2175 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.508076 140216261453696 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.510112 140216261453696 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:09.512333 140216261453696 run_classifier.py:468] label: 1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 10000 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:30:53.968336 140216261453696 run_classifier.py:774] Writing example 10000 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 20000 of 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:31:39.338233 140216261453696 run_classifier.py:774] Writing example 20000 of 25000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f861e2e30f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:32:01.517917 140216261453696 estimator.py:201] Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f861e2e30f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:32:14.740595 140216261453696 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:32:18.990312 140216261453696 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_text/bert_text.py:68: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0415 18:32:19.159283 140216261453696 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/bert_text/bert_text.py:68: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0415 18:32:19.217051 140216261453696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0415 18:32:19.306821 140216261453696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0415 18:32:29.856747 140216261453696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:32:32.516620 140216261453696 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:32:32.521621 140216261453696 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:32:36.891954 140216261453696 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:32:42.399796 140216261453696 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:32:42.668556 140216261453696 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:33:00.476575 140216261453696 basic_session_run_hooks.py:594] Saving checkpoints for 0 into output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.9310819, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:33:19.779300 140216261453696 basic_session_run_hooks.py:249] loss = 0.9310819, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.606597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:36:04.632732 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.606597\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00081365637, step = 100 (164.856 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:36:04.635739 140216261453696 basic_session_run_hooks.py:247] loss = 0.00081365637, step = 100 (164.856 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.654123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:38:37.509228 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.654123\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00023914945, step = 200 (152.876 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:38:37.512139 140216261453696 basic_session_run_hooks.py:247] loss = 0.00023914945, step = 200 (152.876 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.656619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:41:09.804618 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.656619\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0001248228, step = 300 (152.301 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:41:09.813164 140216261453696 basic_session_run_hooks.py:247] loss = 0.0001248228, step = 300 (152.301 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.661308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:43:41.019960 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.661308\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.4920046, step = 400 (151.211 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:43:41.023863 140216261453696 basic_session_run_hooks.py:247] loss = 0.4920046, step = 400 (151.211 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.662448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:46:11.975225 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.662448\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00014706702, step = 500 (150.957 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:46:11.980991 140216261453696 basic_session_run_hooks.py:247] loss = 0.00014706702, step = 500 (150.957 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.66137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:48:43.176526 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.66137\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0001111936, step = 600 (151.199 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:48:43.180157 140216261453696 basic_session_run_hooks.py:247] loss = 0.0001111936, step = 600 (151.199 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.657811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:51:15.195869 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.657811\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 8.958908e-05, step = 700 (152.026 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:51:15.206234 140216261453696 basic_session_run_hooks.py:247] loss = 8.958908e-05, step = 700 (152.026 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.656845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:53:47.438745 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.656845\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.15520567, step = 800 (152.239 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:53:47.444936 140216261453696 basic_session_run_hooks.py:247] loss = 0.15520567, step = 800 (152.239 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.657433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:56:19.545484 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.657433\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0006484295, step = 900 (152.107 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:56:19.552169 140216261453696 basic_session_run_hooks.py:247] loss = 0.0006484295, step = 900 (152.107 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.657641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:58:51.604153 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.657641\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00027398864, step = 1000 (152.059 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 18:58:51.611419 140216261453696 basic_session_run_hooks.py:247] loss = 0.00027398864, step = 1000 (152.059 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.657962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:01:23.588788 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.657962\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00018324461, step = 1100 (151.980 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:01:23.591632 140216261453696 basic_session_run_hooks.py:247] loss = 0.00018324461, step = 1100 (151.980 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.661481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:03:54.764718 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.661481\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0045888545, step = 1200 (151.180 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:03:54.771460 140216261453696 basic_session_run_hooks.py:247] loss = 0.0045888545, step = 1200 (151.180 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.658286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:06:26.674267 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.658286\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00087871874, step = 1300 (151.906 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:06:26.677145 140216261453696 basic_session_run_hooks.py:247] loss = 0.00087871874, step = 1300 (151.906 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.657542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:08:58.755745 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.657542\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00055294577, step = 1400 (152.082 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:08:58.759429 140216261453696 basic_session_run_hooks.py:247] loss = 0.00055294577, step = 1400 (152.082 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.657184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:11:30.920260 140216261453696 basic_session_run_hooks.py:680] global_step/sec: 0.657184\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.00042675994, step = 1500 (152.173 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0415 19:11:30.932696 140216261453696 basic_session_run_hooks.py:247] loss = 0.00042675994, step = 1500 (152.173 sec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lfzoNF_FbusC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}